<!doctype html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=900" />

  <title>Peter Henderson | Fully Convolutional Seq2Seq for Character-Level Dialogue Generation</title>

  <link rel="stylesheet" href="css/reveal.css">
  <link rel="stylesheet" href="css/theme/white.css">
  <link rel="stylesheet" href="css/force.css" type="text/css">
  <!-- Portfolio styles -->
  <link href="https://fonts.googleapis.com/css?family=Abel" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="$/portfolio.css">
</head>

<body>
  <div class="header">
    <!-- <div class="header__logo logo">
      <a href="#/" class="logo__link"><img class="logo__image" src="$/logo_portfolio.png" alt="logo" /></a>
    </div> -->
    <div class="header__menu">
      <div class="header__menu-item"><a class="header__menu-link" href="#/">Introduction</a></div><!--
      --><div class="header__menu-item"><a class="header__menu-link" href="#/motivation">Motivation</a></div><!--
 --><div class="header__menu-item"><a class="header__menu-link" href="#/related">Related Work</a></div><!--
--><div class="header__menu-item"><a class="header__menu-link" href="#/contributions">Contributions</a></div><!--
--><div class="header__menu-item"><a class="header__menu-link" href="#/model">Model</a></div><!--
   --><div class="header__menu-item"><a class="header__menu-link" href="#/experiments">Experiments</a></div><!--
 --><div class="header__menu-item"><a class="header__menu-link" href="#/results">Results</a></div><!--
--><div class="header__menu-item"><a class="header__menu-link" href="#/analysis">Analysis</a></div><!--
--><div class="header__menu-item"><a class="header__menu-link" href="#/conclusion">Conclusion</a></div><!--
   --><div class="header__menu-item"><a class="header__menu-link" href="#/questions">Questions?</a></div><!--
   --><div class="header__menu-item header__menu-item_type_contact"><a class="header__menu-link" href="#/contact">Contact</a></div>
    </div>
  </div>
  <div class="reveal">
    <div class="slides">
      <section>
        <!-- <img src="$/images_pf/face.jpg" class="face"> -->
        <h2>Fully Convolutional Seq2Seq for Character-Level Dialogue Generation</h2>
        <div class="section-subheader">Peter Henderson</div>
        <img src="http://royalvictoria.mcgill.ca/wp-content/uploads/2014/02/logo_video.png" class="face">

      </section>
      <section>
        <section id="motivation">
          <div class="text">
            <h2>Problem and Motivation</h2>
            <div class="section-subheader">Dialogue systems are important for making convenient human-computer interfaces and simulating intelligence in robotic systems.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Dialogue Systems</h2>
            <div class="section-subheader">
              <img class="logo-image" src="https://upload.wikimedia.org/wikipedia/commons/c/cc/Amazon_Alexa_App_Logo.png"/>
              <img class="logo-image" src="http://platformer.cdn.appadvice.com/wp-content/appadvice-v2-media/2015/07/f463462eb980c03a2a66565f0327c158.jpg"/>
              <img class="logo-image" src="https://3.bp.blogspot.com/-PpsSxrSLOLY/V1G_9VFyE1I/AAAAAAAACXE/5lAEDqXzo8chNme_mG47LLHkcguaR1uDwCK4B/s400/WP8-1_Cortana_FirstRun_Hello_01_324x233_CortanaLanding_InvariantCulture_Default.png"/>
              <img class="logo-image" src="http://vignette4.wikia.nocookie.net/marvelmovies/images/0/06/J.A.R.V.I.S..jpg/revision/latest?cb=20130421191808"/>
              <img class="logo-image" src="https://i1.wp.com/thefwoosh.com/wp-content/uploads/2015/08/Medicom-MAFEX-No-012-Star-Wars-C3PO-R2D2-Promo.jpg"/>
            </div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Turing test and beyond...</h2>
            <div class="section-subheader">Goal is to simulate human conversational intelligence.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Different approaches for creating conversational systems</h2>
            <ul>
            <li class="section-subheader">Goal Oriented (for specific tasks <a href="https://arxiv.org/pdf/1605.07683v2.pdf">Facebook</a>, Amazon, Apple, etc.)</li>
            <li class="section-subheader">Pattern Matching (AI in video games)</li>
            <li class="section-subheader"><b><a href="https://arxiv.org/abs/1506.05869">Purely statistical conversational systems</a> (learn from human dialogue corpora)</b></li>
            </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Massive amounts of noisy dialogue data</h2>
            <div class="section-subheader"><b><a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html">Cornell Movie Dialogue Corpus</a></b></div>
            <div class="section-subheader">OpenSubtitles Dataset</div>
            <div class="section-subheader"><a href="https://arxiv.org/abs/1506.08909">Ubuntu Dialogue Corpus</a></div>
            <div class="section-subheader"><a href="https://arxiv.org/abs/1512.05742">Survey</a> of others available...</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Idea</h2>
            <ul>
            <li class="section-subheader">Make unsupervised systems learn statistically relevant responses based on context.</li>
            <li class="section-subheader">Existing models use LSTMs for <b>Seq2Seq</b> but we want to build on <b>causal convolutional architectures</b> which <a href="https://arxiv.org/pdf/1609.03499.pdf">have shown better performance in <i>audio generation</i> tasks than recurrent models.</a></li>
          </ul>
          </div>
        </section>
        <!-- <section data-background-image="$/images_pf/The_Human_Connectome.png" data-background-size="700px" id="complex-brains">
          <h2 style="margin-top: 615px;">Human brains are hard.</h2>
          <span style="float:left; margin-top: -20px; font-size:10px;">Image courtesy of <a href="https://upload.wikimedia.org/wikipedia/commons/c/cd/The_Human_Connectome.png">Wikipedia</a></span>
        </section>
        <section data-background-image="$/images_pf/drosophila.png" data-background-size="400px" id="simple-brain">
          <h2 style="margin-top: 475px;">Insect brains are small.</h2>
          <div class="section-subheader">We need to understand the building blocks and scale up.</div>
          <span style="float:left; margin-top: 25px; font-size:10px;">Image courtesy of <a href="http://www.cell.com/action/showImagesData?pii=S0960-9822%2810%2901522-8">Chiang et al.</a></span>
        </section> -->
        <!-- <section>
<iframe style= "margin-top:20px;" width="100%" height="450" src="https://www.youtube.com/embed/zlv9qi43UmY?autoplay=1&controls=0&showinfo=0&autohide=1" frameborder="0" allowfullscreen></iframe>
<h2>Why community detection?</h2>
<div class="section-subheader">Intracommunity nodes probably work together to accomplish a task.</div>
        </section> -->
      </section>

      <section>
        <section id="related">
          <div class="text">
            <h2>A Neural Conversational Model<br/>(Vinyals and Le, 2015)</h2>
            <div class="section-subheader"><img style="width:50%;" src="https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-01/268a7cd1bf65351bba4eb97aac373d624af2c08f/0-Table1-1.png"/></div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2 style="font-size: 50px;">Recurrent Models and Improvements<br/>In Machine Translation and Dialogue Systems</h2>
            <div class="section-subheader">
              <ul>
                <li style="font-size: 20px;"><a href="http://stanford.edu/%7Elmthang/data/papers/emnlp15_attn.pdf">Effective Approaches to Attention-based Neural Machine Translation</a>. Luong et al., EMNLP 2015.</li>
                <li style="font-size: 20px;"><a href="https://arxiv.org/pdf/1606.04199">Deep Recurrent Models with Fast Forward Connections for Neural Machine Translation</a>.
                Zhou et al, TACL 2016.</li>
                <li style="font-size: 20px;"><a href="https://arxiv.org/pdf/1605.06069.pdf">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a>.
                Serban et al, AAAI 2017.</li>
                <li style="font-size: 20px;"><a href="https://arxiv.org/pdf/1611.06216v1.pdf">Generative Deep Neural Networks for Dialogue: A Short Review</a>.
                Serban et al., arxiv 2016.
                TODO: add more papers
                </li>
              </ul>
          </div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>WaveNet</h2>
            <img src="https://storage.googleapis.com/deepmind-live-cms/documents/BlogPost-Fig2-Anim-160908-r01.gif" alt="Architecture animation">
            <div class="section-subheader">State of the art audio generation using causal convolutions.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>ByteNet</h2>
            <div class="section-subheader"><img src="$/images_pf/bytenet.png"/></div>
            <div class="section-subheader">Fully convolutional encoder-decoder for machine translation</div>
          </div>
        </section>
      </section>

      <section>
        <section id="contributions">
          <div class="text">
            <h2>Fully Convolutional <br/>Character-Level Conversational System</h2>
            <div class="section-subheader">Fully convolutional dialogue system based on causal convolutions not applied previously to authors knowledge.</div>
          </div>
        </section>
      </section>

      <section>
        <section id="model">
          <div class="text">
            <h2>Model and Theory</h2>
            <div class="section-subheader">Use ByteNet architecture, and modify with extra conditional gate to make context more prevalent.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Convolutional Neural Networks</h2>
            TODO
            <!-- <div class="section-subheader"><img src="$/images_pf/bytenet.png"/></div> -->
          </div>
        </section>
        <section>
          <div class="text">
            <h2>ByteNet Architecture</h2>
            <div class="section-subheader"><img src="$/images_pf/bytenet.png"/></div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Modified ByteNet Architecture</h2>
            <div class="section-subheader"><img src="$/images_pf/modified_bytenet.png"/></div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Modified ByteNet Architecture</h2>
            <div class="section-subheader">TODO: conditional gate taken from WaveNet</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Objective Function</h2>
            <div class="section-subheader">Softmax Categorical Cross Entropy (TODO equations). L2 Regularization. MaxProp.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Beam Search</h2>
            <div class="section-subheader">TODO: info on beam search</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Word-Level Seq2Seq Baseline With Attention</h2>
            <div class="section-subheader"><img src="https://www.tensorflow.org/versions/r0.12/images/basic_seq2seq.png"/>
              Used <a href="https://github.com/harvardnlp/seq2seq-attn">Harvard Torch Implementation</a> default parameters (500 hidden units, 2 layers).
            </div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Used repositories and technologies</h2>
            <ul>
            <li class="section-subheader">Harvard Seq2Seq with Attention/BeamSearch (Torch/Lua)</li>
            <li class="section-subheader">Tensorflow/Sugartensor</li>
            <li class="section-subheader">Used <a href="https://github.com/buriburisuri/ByteNet">Jamonglabs implementation of Bytenet</a> as base. Heavily modified.</li>
            <li class="section-subheader">Wrapper for processing Cornell corpus heavily modified from <a href="https://github.com/pralexa/SimpleBot/blob/master/cornell_movie_dialog.py">this Github Repo</a>.
          </li>
          <li class="section-subheader">Perl implementation of BLEU score borrowed from <a href="https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl">Moses Translation Project</a></li>
        </ul>
        </section>
      </section>


      <section>
        <section id="experiments">
          <div class="text">
            <h2>Dataset</h2>
            <div class="section-subheader">Cornell Movie Dialogue Corpus</div>
            <div style="font-size: 18px;" class="section-subheader">Smaller, reasonable training time.</div>
            <div style="font-size: 18px;" class="section-subheader">Conversations in variety of contexts.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Pruning</h2>
            <div class="section-subheader">To reduce size of the model only take sentences with l.t. 50 characters. Otherwise takes too long to converge.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Split</h2>
            <div class="section-subheader">80% training(~80k dialogue pairs)/10% validation (~8k dialogue pairs)/10% testing(~8k dialogue pairs)</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Evaluation Metrics</h2>
            <div class="section-subheader">BLEU score as in TODO and TODO.</div>
            <div class="section-subheader">Questionaire as in several other works.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Questionaire</h2>
            <ul>
            <li class="section-subheader">Rate 3 responses (baseline, ours, and human response)</li>
            <li class="section-subheader">3 different criteria: (1) which is the most believable response; (2) which response is the most grammatically correct; (3) which response provides the most believable information</li>
            <li class="section-subheader">Rate on scale: Excellent(5), Good(4), Acceptable(3), Mediocre(2), and Bad(1)</li>
            <li class="section-subheader">Questions and statements taken mostly from: TODO Vinyals.</li>
            <li class="section-subheader">Idea from questionaire taken from <a href="https://openreview.net/pdf?id=HJDdiT9gl">Shao et al., 2016</a>.</li>
          </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Experiment 1: Raw ByteNet Architecture w/ Beam Search</h2>
            <div class="section-subheader">Almost exclusively "I don't know"</div>
            <div class="section-subheader">Some larger models didn't converge at all.</div>
            <div class="section-subheader">Best Bleu Score on Validation Set: 1.03</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Experiment 2: Modified ByteNet Architecture w/ Beam Search</h2>
            <div class="section-subheader">Removes "I don't know" problem, more variable responses.</div>
            <div class="section-subheader">Bleu Score on Validation Set: TODO</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Baseline: Word-Level Seq2Seq with Attention and Beam Search</h2>
            <div class="section-subheader">Bleu Score on Validation Set: TODO</div>
          </div>
        </section>
      </section>


      <section>
        <section id="results">
          <div class="text">
            <h2>Results (BLEU Score)</h2>
            <ul>
              <li class="section-subheader">Word Level Seq2Seq with Attention: 1.30 </li>
              <li class="section-subheader">Original Character-level ByteNet: 1.13</li>
              <li class="section-subheader">Modified Character-level ByteNet: TODO</li>
            </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Results (Questionaire Scores)</h2>
            <ul>
            <li class="section-subheader">Most believable response (average rating)</li>
            <li class="section-subheader">Baseline Seq2Seq: </li>
            <li class="section-subheader">Modified Character-level ByteNet: </li>
            <li class="section-subheader">Human: </li>
          </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Results (Questionaire Scores)</h2>
            <ul>
            <li class="section-subheader">Most believable response (average rating)</li>
            <li class="section-subheader">Baseline Seq2Seq: </li>
            <li class="section-subheader">Modified Character-level ByteNet: </li>
            <li class="section-subheader">Human Average rank: </li>
            </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Results (Questionaire Scores)</h2>
            <ul>
            <li class="section-subheader">Most informative response (average rating)</li>
            <li class="section-subheader">Baseline Seq2Seq: </li>
            <li class="section-subheader">Modified Character-level ByteNet: </li>
            <li class="section-subheader">Human Average rank: </li>
            </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Results (Sample Responses)</h2>
            <div class="section-subheader">TODO</div>
          </div>
        </section>
      </section>

      <section>
        <section id="analysis">
          <div class="text">
            <h2>Analysis and Discussion</h2>
            <div class="section-subheader">The <b>"I don't know"</b> problem</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Analysis and Discussion</h2>
            <div class="section-subheader">Low BLEU scores.</div>
            <div class="section-subheader">Likely due to inneffectiveness of BLEU as a metric for dialogue systems.</div>
            <div class="section-subheader">Small and noisy dataset.</div>
          </div>
        </section>
        <section >
          <div class="text">
            <h2>Analysis and Discussion</h2>
            <div class="section-subheader">Examples of Noise in dataset.</div>
            <div class="section-subheader">TODO</div>
          </div>
        </section>
        <section >
          <div class="text">
            <h2>Analysis and Discussion</h2>
            <div class="section-subheader">Effectiveness of Evaluation Metrics</div>
            <div class="section-subheader">TODO: alternatives</div>
            <div class="section-subheader">TODO: spellcheck</div>
          </div>
        </section>
        <section >
          <div class="text">
            <h2>Analysis and Discussion</h2>
            <div class="section-subheader"><b>Prohibitive Training Time</b></div>
            <ul>
            <li class="section-subheader">Extremely long (~2 days for model to converge on ~80k sentence pairs)</li>
            <li class="section-subheader">Others have reported taking a month to converge on OpenSubtitles corpus with large Seq2Seq model (TODO cite)</li>
            <li class="section-subheader">Possible optimizations can be made such as caching convolutions as in <a href="https://arxiv.org/abs/1611.09482">Fast Wavenet</a>. </li>
            </ul>
          </div>
        </section>
      </section>

      <section>
        <section id="conclusion">
          <div class="text">
            <h2>Conclusion</h2>
            <div class="section-subheader">Character level models show promise since you don't have to explicitly model word space. New words automatically learned in the corpus.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Conclusion</h2>
            <div class="section-subheader">Modified character-level ByteNet architecture competitive with basic word-level Seq2Seq.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Future Work (beyond project)</h2>
            <ul>
            <li class="section-subheader">Train on larger OpenSubtitles corpus with bigger/deeper model (prohibitive with current hardware/timeframe).</li>
            <li class="section-subheader">Run larger system against more information oriented questionairre.</li>
            <li class="section-subheader">Pretrain with Wikipedia Corpus for added knowledge base (TODO: cite paper Topic Aware or Context aware modeling).</li>
            <li class="section-subheader">Add longer term contexts as extra conditional gates.</li>
            <li class="section-subheader">Add speaker information as a condition, work toward interactive alignment.</li>
            </ul>
          </div>
        </section>
      </section>

      <section>
        <section id="questions">
          <h2>Questions</h2>
          <div class="section-subheader">AMA.</div>
          <br/><span style="font-size: 10pt;">(Did you like the web presentation?)</span>
          <br/><span style="font-size: 10pt;">(Want to know anything about the algorithms or data?)</span>
        </section>
      </section>



      <section id="contact">
        <h2>Contact</h2>
        <div class="section-subheader">
          Any later questions, you can ask them by email!
          <br/><span style="font-size: 10pt;">(All citations and sources are linked inline.)</span>
          <br><a class="contact-link contact-link_type_email" href="mailto:peter.henderson@mail.mcgill.ca">peter.henderson@mail.mcgill.ca</a>
        </div>
      </section>
    </div>
  </div>
  <div class="navigation-hint">use arrow keys<br>to navigate</div>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/headjs/0.96/head.min.js"></script>
  <script src="js/reveal.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script type="text/javascript" src="js/d3.min.js"></script>
  <script type="text/javascript" src="js/d3.geom.min.js"></script>
  <script type="text/javascript" src="js/d3.layout.min.js"></script>
  <script type="text/javascript" src="js/force.js"></script>
  <script>
    // window.onresize = function(event) {
    //   console.log('I am resized!', window.innerWidth, window.innerHeight);
    // };

    var numberOfPixels = 0;

    var $navigationHint = $('.navigation-hint');

    var $allMenuItems = $('.header__menu-item');
    // console.log('all menu items', $allMenuItems);

    var selectCurrentMenuItem = function() {

      var currentHash = window.location.hash;
      // console.log('location change !!!!', currentHash);

      // numberOfPixels = numberOfPixels + 1;
      // document.body.style = 'border: ' + numberOfPixels + 'px solid red';
      //
      // $('.header__menu-link, h2').css({
      //   'border': numberOfPixels + 'px solid red'
      // });

      // $allMenuItems.css({
      //   'outline': '1px solid red'
      // }).toggleClass('haha');

      $allMenuItems.removeClass('header__menu-item_state_current');

      $currentMenuItem = $allMenuItems.filter(function(index, element) {
        var linkHref = $(element).find('a').attr('href');
        // console.log('checking filter', index, element, linkHref);
        var shouldMakeCurrent = linkHref == currentHash;
        if (linkHref != '#/') {
          shouldMakeCurrent = currentHash.indexOf(linkHref) == 0;
        }
        return shouldMakeCurrent;
      });
      $currentMenuItem.addClass('header__menu-item_state_current')

      // Toggle navigation hint
      if (currentHash == '#/') {
        $navigationHint.show();
      } else {
        $navigationHint.hide();
      }

      // Toggle navigation hint (alternative solution)
      // var needToShowNavigationHint = false;
      // if (currentHash == '#/') {
      //   needToShowNavigationHint = true;
      // }
      // $('.navigation-hint').toggle(needToShowNavigationHint);

      // trackPageView();
    };

    window.onhashchange = selectCurrentMenuItem;
    selectCurrentMenuItem();

    // More info https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
      history: true,

        math: {
            mathjax: 'https://cdn.mathjax.org/mathjax/latest/MathJax.js',
            config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
        },

        dependencies: [
            { src: 'js/math.js', async: true }
        ]
      // // More info https://github.com/hakimel/reveal.js#dependencies
      // dependencies: [{
      //   src: 'plugin/markdown/marked.js'
      // }, {
      //   src: 'plugin/markdown/markdown.js'
      // }, {
      //   src: 'plugin/notes/notes.js',
      //   async: true
      // }, {
      //   src: 'plugin/highlight/highlight.js',
      //   async: true,
      //   callback: function() {
      //     hljs.initHighlightingOnLoad();
      //   }
      // }]
    });
  </script>


  <script>
    // Load the IFrame Player API code asynchronously.
    var tag = document.createElement('script');
    tag.src = "https://www.youtube.com/player_api";
    var firstScriptTag = document.getElementsByTagName('script')[0];
    firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);
    // Replace the 'ytplayer' element with an <iframe> and
    // YouTube player after the API code downloads.
    var player;
    function onYouTubePlayerAPIReady() {
      player = new YT.Player('ytplayer', {
        width: '920',
        height: '490',
        videoId: 'F4lc9cY4fMM',
        playerVars: {
          'wmode': 'opaque',
          'autoplay': 1,
          'controls': 0 ,
          'showinfo': 0,
          'start': 20,
          'rel': 0,
          'loop': 1,
        },
        events:{
          'onReady':onPlayerReady
        }
     });
    }
    function onPlayerReady(event) {
      event.target.mute();
    }

//     Reveal.addEventListener( 'slidechanged', function( event ) {
//     MathJax.Hub.Rerender();
// } );
  </script>

</body>

</html>
