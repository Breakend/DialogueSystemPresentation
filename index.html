<!doctype html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=900" />

  <title>Peter Henderson | Fully Convolutional Seq2Seq for Character-Level Dialogue Generation</title>

  <link rel="stylesheet" href="css/reveal.css">
  <link rel="stylesheet" href="css/theme/white.css">
  <link rel="stylesheet" href="css/force.css" type="text/css">
  <!-- Portfolio styles -->
  <link href="https://fonts.googleapis.com/css?family=Abel" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="$/portfolio.css">
</head>

<body>
  <div class="header">
    <!-- <div class="header__logo logo">
      <a href="#/" class="logo__link"><img class="logo__image" src="$/logo_portfolio.png" alt="logo" /></a>
    </div> -->
    <div class="header__menu">
      <div class="header__menu-item"><a class="header__menu-link" href="#/">Introduction</a></div><!--
      --><div class="header__menu-item"><a class="header__menu-link" href="#/motivation">Motivation</a></div><!--
 --><div class="header__menu-item"><a class="header__menu-link" href="#/related">Related Work</a></div><!--
--><div class="header__menu-item"><a class="header__menu-link" href="#/contributions">Contributions</a></div><!--
--><div class="header__menu-item"><a class="header__menu-link" href="#/model">Model</a></div><!--
   --><div class="header__menu-item"><a class="header__menu-link" href="#/experiments">Experiments</a></div><!--
 --><div class="header__menu-item"><a class="header__menu-link" href="#/results">Results</a></div><!--
--><div class="header__menu-item"><a class="header__menu-link" href="#/analysis">Analysis</a></div><!--
--><div class="header__menu-item"><a class="header__menu-link" href="#/conclusion">Conclusion</a></div><!--
   --><div class="header__menu-item"><a class="header__menu-link" href="#/questions">Questions?</a></div><!--
   --><div class="header__menu-item header__menu-item_type_contact"><a class="header__menu-link" href="#/contact">Contact</a></div>
    </div>
  </div>
  <div class="reveal">
    <div class="slides">
      <section>
        <!-- <img src="$/images_pf/face.jpg" class="face"> -->
        <h2>Fully Convolutional Seq2Seq for Character-Level Dialogue Generation</h2>
        <div class="section-subheader">Peter Henderson</div>
        <img src="http://royalvictoria.mcgill.ca/wp-content/uploads/2014/02/logo_video.png" class="face">

      </section>
      <section>
        <section id="motivation">
          <div class="text">
            <h2>Problem and Motivation</h2>
            <div class="section-subheader">Dialogue systems are important for making convenient human-computer interfaces and simulating intelligence in robotic systems.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Dialogue Systems</h2>
            <div class="section-subheader">
              <img class="logo-image" src="https://upload.wikimedia.org/wikipedia/commons/c/cc/Amazon_Alexa_App_Logo.png"/>
              <img class="logo-image" src="http://platformer.cdn.appadvice.com/wp-content/appadvice-v2-media/2015/07/f463462eb980c03a2a66565f0327c158.jpg"/>
              <img class="logo-image" src="https://3.bp.blogspot.com/-PpsSxrSLOLY/V1G_9VFyE1I/AAAAAAAACXE/5lAEDqXzo8chNme_mG47LLHkcguaR1uDwCK4B/s400/WP8-1_Cortana_FirstRun_Hello_01_324x233_CortanaLanding_InvariantCulture_Default.png"/>
              <img class="logo-image" src="http://vignette4.wikia.nocookie.net/marvelmovies/images/0/06/J.A.R.V.I.S..jpg/revision/latest?cb=20130421191808"/>
              <img class="logo-image" src="https://i1.wp.com/thefwoosh.com/wp-content/uploads/2015/08/Medicom-MAFEX-No-012-Star-Wars-C3PO-R2D2-Promo.jpg"/>
            </div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Turing test and beyond...</h2>
            <div class="section-subheader">Goal is to simulate human conversational intelligence.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Different approaches for creating conversational systems</h2>
            <ul>
            <li class="section-subheader">Goal Oriented (for specific tasks <a href="https://arxiv.org/pdf/1605.07683v2.pdf">Facebook</a>, Amazon, Apple, etc.)</li>
            <li class="section-subheader">Pattern Matching (AI in video games)</li>
            <li class="section-subheader"><b><a href="https://arxiv.org/abs/1506.05869">Purely statistical conversational systems</a> (learn from human dialogue corpora)</b></li>
            </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Massive amounts of noisy dialogue data</h2>
            <div class="section-subheader"><b><a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html">Cornell Movie Dialogue Corpus</a></b></div>
            <div class="section-subheader"><a href="http://opus.lingfil.uu.se/OpenSubtitles2016.php">OpenSubtitles Dataset</a></div>
            <div class="section-subheader"><a href="https://arxiv.org/abs/1506.08909">Ubuntu Dialogue Corpus</a></div>
            <div class="section-subheader"><a href="https://arxiv.org/abs/1512.05742">Survey</a> of others available...</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Idea</h2>
            <ul>
            <li class="section-subheader">Make unsupervised systems learn statistically relevant responses based on context.</li>
            <li class="section-subheader">Existing models use LSTMs for <b>Seq2Seq</b> but we want to build on <b>causal convolutional architectures</b> which <a href="https://arxiv.org/pdf/1609.03499.pdf">have shown better performance in <i>audio generation</i> tasks than recurrent models.</a></li>
          </ul>
          </div>
        </section>
      </section>

      <section>
        <section id="related">
          <div class="text">
            <h2>A Neural Conversational Model</h2>
            <div class="section-subheader"><a href="https://arxiv.org/abs/1506.05869">(Vinyals and Le, 2015)</a><br/><img style="width:50%;" src="https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-01/268a7cd1bf65351bba4eb97aac373d624af2c08f/0-Table1-1.png"/></div>
          </div>
        </section>
        <section id="related">
          <div class="text">
            <h2>A Neural Conversational Model</h2>
            <div class="section-subheader">Uses LSTMs <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">as described here.</a><br/><img style="width:50%;" src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png"/></div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2 style="font-size: 50px;">Recurrent Models and Improvements<br/>In Machine Translation and Dialogue Systems</h2>
            <div class="section-subheader">
              <ul>
                <li style="font-size: 20px;"><a href="http://stanford.edu/%7Elmthang/data/papers/emnlp15_attn.pdf">Effective Approaches to Attention-based Neural Machine Translation</a>. Luong et al., EMNLP 2015.</li>
                <li style="font-size: 20px;"><a href="https://arxiv.org/pdf/1606.04199">Deep Recurrent Models with Fast Forward Connections for Neural Machine Translation</a>.
                Zhou et al, TACL 2016.</li>
                <li style="font-size: 20px;"><a href="https://arxiv.org/pdf/1605.06069.pdf">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a>.
                Serban et al, AAAI 2017.</li>
                <li style="font-size: 20px;"><a href="https://arxiv.org/pdf/1611.06216v1.pdf">Generative Deep Neural Networks for Dialogue: A Short Review</a>.
                Serban et al., arxiv 2016.
                </li>
              </ul>
          </div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2><a href="https://arxiv.org/abs/1609.03499">WaveNet</a></h2>
            <img src="https://storage.googleapis.com/deepmind-live-cms/documents/BlogPost-Fig2-Anim-160908-r01.gif" alt="Architecture animation">
            <div class="section-subheader">State of the art audio generation using causal convolutions.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2><a href="https://arxiv.org/abs/1610.10099">ByteNet</a></h2>
            <div class="section-subheader"><img src="$/images_pf/bytenet.png"/></div>
            <div class="section-subheader">Fully convolutional encoder-decoder for machine translation</div>
          </div>
        </section>
      </section>

      <section>
        <section id="contributions">
          <div class="text">
            <h2>Fully Convolutional <br/>Character-Level Conversational System</h2>
            <div class="section-subheader">Fully convolutional dialogue system based on causal convolutions not applied previously to authors knowledge.</div>
          </div>
        </section>
      </section>

      <section>
        <section id="model">
          <div class="text">
            <h2>Model and Theory</h2>
            <div class="section-subheader">Use ByteNet architecture, and modify with extra conditional gate to make context more prevalent.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Formulation</h2>

            <div class="section-subheader">Model probability of next character based on previous output and context.</div>
            <div class="section-subheader">$p(t|s) = \prod_{i=0}^N p(t_i|t_{\lt i}, s)$</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Dilated and Causal Convolutions</h2>
            <div class="section-subheader">Causal convolutions only rely on previous timesteps. Dilated convolutions add skipping for modeling longer time-series more efficiently.</div>
            <img src="https://storage.googleapis.com/deepmind-live-cms/documents/BlogPost-Fig2-Anim-160908-r01.gif" alt="Architecture animation">
          </div>
        </section>
        <section>
          <div class="text">
            <h2>ByteNet Architecture</h2>
            <div class="section-subheader"><img src="$/images_pf/bytenet.png"/></div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Modified ByteNet Architecture</h2>
            <div class="section-subheader"><img src="$/images_pf/modified_bytenet.png"/></div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Modified ByteNet Architecture</h2>
            <div class="section-subheader">$z=\tanh(W*x + V*h) \odot \sigma (W*x + V*h)$</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Objective Function<br/>Softmax Categorical Cross Entropy</h2>
            <div class="section-subheader"></div>
            <div class="section-subheader">$L(W, x) = - \ln (\frac{e^{f_k}}{\sum_j e^{f_j}})$</div>
            <div class="section-subheader"><a href="https://cs231n.github.io/linear-classify/#softmax-classifier">From Stanford CS231 Notes</a>.</div>

          </div>
        </section>
        <section>
          <div class="text">
            <h2>MaxProp</h2>
            <ul>
            <li class="section-subheader">According to the authors, <b>prevents gradient explosions</b>, <b>numerically stable.</b></li>
            <li class="section-subheader">Provided by SugarTensor wrapper for Tensorflow.</li>
            <li class="section-subheader">See <a href="http://jamonglab.com/maxprop/">their website</a> for more details.</li>
          </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Beam Search</h2>
            <ul>
              <li class="section-subheader">When $B=1$, essentially Best-First Search </li>
              <li class="section-subheader">When $B=\infty$, essentially Breadth-First Search </li>
              <li class="section-subheader">Beam heuristic is sum of log probability.</li>
            </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Word-Level Seq2Seq Baseline With Attention</h2>
            <div class="section-subheader"><img src="https://www.tensorflow.org/versions/r0.12/images/basic_seq2seq.png"/>
              Used <a href="https://github.com/harvardnlp/seq2seq-attn">Harvard Torch Implementation</a> default parameters (500 hidden units, 2 layers).
            </div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Used repositories and technologies</h2>
            <ul>
            <li class="section-subheader">Harvard Seq2Seq with Attention/BeamSearch (Torch/Lua)</li>
            <li class="section-subheader">Tensorflow/Sugartensor</li>
            <li class="section-subheader">Used <a href="https://github.com/buriburisuri/ByteNet">Jamonglabs implementation of Bytenet</a> as base. Heavily modified.</li>
            <li class="section-subheader">Wrapper for processing Cornell corpus heavily modified from <a href="https://github.com/pralexa/SimpleBot/blob/master/cornell_movie_dialog.py">this Github Repo</a>.
          </li>
          <li class="section-subheader">Perl implementation of BLEU score borrowed from <a href="https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl">Moses Translation Project</a></li>
        </ul>
        </section>
      </section>


      <section>
        <section id="experiments">
          <div class="text">
            <h2>Dataset</h2>
            <div class="section-subheader">Cornell Movie Dialogue Corpus</div>
            <div style="font-size: 18px;" class="section-subheader">Smaller, reasonable training time.</div>
            <div style="font-size: 18px;" class="section-subheader">Conversations in variety of contexts.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Pruning</h2>
            <div class="section-subheader">To reduce size of the model only take sentences with l.t. 50 characters. Otherwise takes too long to converge.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Split</h2>
            <div class="section-subheader">80% training(~80k dialogue pairs)/10% validation (~8k dialogue pairs)/10% testing(~8k dialogue pairs)</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Evaluation Metrics</h2>
            <ul>
            <li class="section-subheader">BLEU score as in <a href="https://arxiv.org/abs/1510.03055">Li et al., 2015</a> and <a href="https://arxiv.org/abs/1603.06155">Li et al., 2016.</a></li>
            <li class="section-subheader">Questionaire as in <a href="https://openreview.net/pdf?id=HJDdiT9gl">Shao et al., 2016</a> and <a href="https://arxiv.org/abs/1506.05869">(Vinyals and Le, 2015)</a>.</li>
          </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Questionaire</h2>
            <ul>
            <li class="section-subheader">Rate 3 responses (baseline, ours, and human response)</li>
            <li class="section-subheader">3 different criteria: (1) appropriateness (is it a valid answer); (2) grammatical correctness; (3) diversity of the response (is it more than just "I don't know.") </li>
            <li class="section-subheader">Rate on scale: Excellent(5), Good(4), Acceptable(3), Mediocre(2), and Bad(1)</li>
            <li class="section-subheader">Questions and statements taken mostly from: <a href="https://arxiv.org/abs/1506.05869">(Vinyals and Le, 2015)</a>. (50 total)</li>
            <li class="section-subheader">Idea from questionaire taken from <a href="https://openreview.net/pdf?id=HJDdiT9gl">Shao et al., 2016</a>.</li>
          </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Experiment 1: Raw ByteNet Architecture w/ Beam Search</h2>
            <div class="section-subheader">Almost exclusively "I don't know"</div>
            <div class="section-subheader">Some larger models didn't converge at all.</div>
            <div class="section-subheader">Best Bleu Score on Validation Set: 1.56</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Experiment 2: Modified ByteNet Architecture w/ Beam Search</h2>
            <div class="section-subheader">Removes "I don't know" problem, more variable responses.</div>
            <div class="section-subheader">Bleu Score on Validation Set: TODO</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Baseline: Word-Level Seq2Seq with Attention and Beam Search</h2>
            <div class="section-subheader">Bleu Score on Validation Set: 1.23</div>
          </div>
        </section>
      </section>


      <section>
        <section id="results">
          <div class="text">
            <h2>Results (BLEU Score)</h2>
            <ul>
              <li class="section-subheader">Word Level Seq2Seq with Attention: 1.30 </li>
              <li class="section-subheader">Original Character-level ByteNet: 1.46</li>
              <li class="section-subheader">Modified Character-level ByteNet: TODO</li>
            </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Results (Questionaire Scores)</h2>
            <ul>
            <li class="section-subheader">Appropriateness of response (average rating)</li>
            <li class="section-subheader">Baseline Seq2Seq: 2.16</li>
            <li class="section-subheader">Baseline ByteNet: 2.23</li>
            <li class="section-subheader">Modified Character-level ByteNet: TODO</li>
            <li class="section-subheader">Human: 4.68</li>
          </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Results (Questionaire Scores)</h2>
            <ul>
            <li class="section-subheader">Grammaticality (average rating)</li>
            <li class="section-subheader">Baseline Seq2Seq: 5</li>
            <li class="section-subheader">Baseline ByteNet: 4.59</li>
            <li class="section-subheader">Modified Character-level ByteNet: </li>
            <li class="section-subheader">Human Average rank: 5</li>
            </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Results (Questionaire Scores)</h2>
            <ul>
            <li class="section-subheader">Information Gain/Diversity (average rating)</li>
            <li class="section-subheader">Baseline Seq2Seq: 1.45</li>
            <li class="section-subheader">Baseline ByteNet: 1.72</li>
            <li class="section-subheader">Modified Character-level ByteNet: TODO</li>
            <li class="section-subheader">Human Average rank: 4.26</li>
            </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Results (Sample Responses Seq2Seq)</h2>
            <ul>
            <li class="section-subheader"><b>How are you?</b> Good.</li>
            <li class="section-subheader"><b>Where are you from?</b> Home.</li>
            <li class="section-subheader"><b>Can a cat fly?</b> How can you do that?</li>
            <li class="section-subheader"><b>How many legs does a cat have?</b> I don't know.</li>
            <li class="section-subheader"><b> What is the purpose of life?</b> I don't know.</li>
          </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Results (Baseline ByteNet)</h2>
            <ul>
            <li class="section-subheader"><b>How are you?</b> What do you mean?</li>
            <li class="section-subheader"><b>Where are you from?</b> I don't know.</li>
            <li class="section-subheader"><b>Can a cat fly?</b> Sure.</li>
            <li class="section-subheader"><b>How many legs does a cat have?</b> I don't know.</li>
            <li class="section-subheader"><b> What is the purpose of life?</b> The money.</li>
          </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Results (Modified ByteNet)</h2>
            <ul>
            <li class="section-subheader"><b>How are you?</b> I don't know.  I'm sorry.</li>
            <li class="section-subheader"><b>Where are you from?</b> Nowhere....</li>
            <li class="section-subheader"><b>Can a cat fly?</b> You got it!</li>
            <li class="section-subheader"><b>How many legs does a cat have?</b> Five.</li>
            <li class="section-subheader"><b> What is the purpose of life?</b> Nothing.  I'm sorry.</li>
          </ul>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Results (Sample Responses Human)</h2>
            <ul>
            <li class="section-subheader"><b>How are you?</b> Good. How about you?</li>
            <li class="section-subheader"><b>Where are you from?</b> Kentucky.</li>
            <li class="section-subheader"><b>Can a cat fly?</b>No, of course not.</li>
            <li class="section-subheader"><b>How many legs does a cat have?</b> It has four legs.</li>
            <li class="section-subheader"><b> What is the purpose of life?</b>To enjoy it.</li>
          </ul>
          </div>
        </section>
      </section>

      <section>
        <section id="analysis">
          <div class="text">
            <h2>Analysis and Discussion</h2>
            <div class="section-subheader">The <b>"I don't know"</b> problem</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Analysis and Discussion</h2>
            <div class="section-subheader">Low BLEU scores.</div>
            <div class="section-subheader">Partly due to inneffectiveness of BLEU as a metric for dialogue systems.</div>
            <div class="section-subheader">Small and noisy dataset.</div>
          </div>
        </section>
        <section >
          <div class="text">
            <h2>Analysis and Discussion</h2>
            <div class="section-subheader">Examples of Noise in dataset.</div>
            <ul>
            <li class="section-subheader"><b>Divorced</b> No, I...</li>
            <li class="section-subheader"><b>I must be going nuts...</b> Nancy?</li>
            <li class="section-subheader"><b>She's got other problems, of course...</b> Her mother needs an operation...</li>
            <li class="section-subheader"><b>A couple blocks! About six!</b> We work there!</li>
          </ul>
          </div>
        </section>
        <section >
          <div class="text">
            <h2>Analysis and Discussion</h2>
            <div class="section-subheader">Alternative Evaluation Metrics</div>
            <div class="section-subheader">BLEU score not great. Maybe <a href="https://openreview.net/pdf?id=HJ5PIaseg">ADEM better</a> (but not yet published)?</div>
          </div>
        </section>
        <section >
          <div class="text">
            <h2>Analysis and Discussion</h2>
            <div class="section-subheader"><b>Prohibitive Training Time</b></div>
            <ul>
            <li class="section-subheader">Extremely long (~2 days for model to converge on ~80k sentence pairs)</li>
            <li class="section-subheader">Others have reported taking a month to converge on datsets of size equivalent to OpenSubtitles corpus with Seq2Seq model as in <a href="https://www.aclweb.org/anthology/P/P16/P16-1094.pdf">Li et al., 2016</a></li>
            <li class="section-subheader">Possible optimizations can be made such as caching convolutions as in <a href="https://arxiv.org/abs/1611.09482">Fast Wavenet</a>. </li>
            </ul>
          </div>
        </section>
        <section >
          <div class="text">
            <h2>Modified ByteNet Strengths</h2>
            <ul>
            <li class="section-subheader">More diverse responses</li>
            <li class="section-subheader">Can model character level phenomena like ellipses...</li>
            <li class="section-subheader">Learns to model language.</li>
          </ul>
          </div>
        </section>
        <section >
          <div class="text">
            <h2>Modified ByteNet Weaknesses</h2>
            <ul>
            <li class="section-subheader">Still some noisy output</li>
            <li class="section-subheader">Needs larger model for effective responses</li>
            <li class="section-subheader">Data hungry model.</li>
          </ul>
          </div>
        </section>
      </section>

      <section>
        <section id="conclusion">
          <div class="text">
            <h2>Conclusion</h2>
            <div class="section-subheader">Character level models show promise since you don't have to explicitly model word space. New words automatically learned in the corpus.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Conclusion</h2>
            <div class="section-subheader">Modified character-level ByteNet architecture competitive with basic word-level Seq2Seq.</div>
          </div>
        </section>
        <section>
          <div class="text">
            <h2>Future Work (beyond project)</h2>
            <ul>
            <li class="section-subheader">Train on larger OpenSubtitles corpus with bigger/deeper model (prohibitive with current hardware/timeframe).</li>
            <li class="section-subheader">Run larger system against more information oriented questionairre.</li>
            <li class="section-subheader">Pretrain with Wikipedia Corpus for added knowledge base as in <a href="https://arxiv.org/pdf/1606.08340.pdf">Xing et al., 2016.</a></li>
            <li class="section-subheader">Add longer term contexts as extra conditional gates.</li>
            <li class="section-subheader">Add speaker information as a condition, work toward <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3384290/">interactive alignment.</a></li>
            </ul>
          </div>
        </section>
      </section>

      <section>
        <section id="questions">
          <h2>Questions</h2>
          <div class="section-subheader">AMA.</div>
          <br/><span style="font-size: 10pt;">(Did you like the web presentation?)</span>
          <br/><span style="font-size: 10pt;">(Want to know anything about the algorithms or data?)</span>
        </section>
      </section>



      <section id="contact">
        <h2>Contact</h2>
        <div class="section-subheader">
          Any later questions, you can ask them by email!
          <br/><span style="font-size: 10pt;">(All citations and sources are linked inline.)</span>
          <br><a class="contact-link contact-link_type_email" href="mailto:peter.henderson@mail.mcgill.ca">peter.henderson@mail.mcgill.ca</a>
        </div>
      </section>
    </div>
  </div>
  <div class="navigation-hint">use arrow keys<br>to navigate</div>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/headjs/0.96/head.min.js"></script>
  <script src="js/reveal.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
  <script type="text/javascript" src="js/d3.min.js"></script>
  <script type="text/javascript" src="js/d3.geom.min.js"></script>
  <script type="text/javascript" src="js/d3.layout.min.js"></script>
  <script type="text/javascript" src="js/force.js"></script>
  <script>
    // window.onresize = function(event) {
    //   console.log('I am resized!', window.innerWidth, window.innerHeight);
    // };

    var numberOfPixels = 0;

    var $navigationHint = $('.navigation-hint');

    var $allMenuItems = $('.header__menu-item');
    // console.log('all menu items', $allMenuItems);

    var selectCurrentMenuItem = function() {

      var currentHash = window.location.hash;
      // console.log('location change !!!!', currentHash);

      // numberOfPixels = numberOfPixels + 1;
      // document.body.style = 'border: ' + numberOfPixels + 'px solid red';
      //
      // $('.header__menu-link, h2').css({
      //   'border': numberOfPixels + 'px solid red'
      // });

      // $allMenuItems.css({
      //   'outline': '1px solid red'
      // }).toggleClass('haha');

      $allMenuItems.removeClass('header__menu-item_state_current');

      $currentMenuItem = $allMenuItems.filter(function(index, element) {
        var linkHref = $(element).find('a').attr('href');
        // console.log('checking filter', index, element, linkHref);
        var shouldMakeCurrent = linkHref == currentHash;
        if (linkHref != '#/') {
          shouldMakeCurrent = currentHash.indexOf(linkHref) == 0;
        }
        return shouldMakeCurrent;
      });
      $currentMenuItem.addClass('header__menu-item_state_current')

      // Toggle navigation hint
      if (currentHash == '#/') {
        $navigationHint.show();
      } else {
        $navigationHint.hide();
      }

      // Toggle navigation hint (alternative solution)
      // var needToShowNavigationHint = false;
      // if (currentHash == '#/') {
      //   needToShowNavigationHint = true;
      // }
      // $('.navigation-hint').toggle(needToShowNavigationHint);

      // trackPageView();
    };

    window.onhashchange = selectCurrentMenuItem;
    selectCurrentMenuItem();

    // More info https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
      history: true,

        math: {
            mathjax: 'https://cdn.mathjax.org/mathjax/latest/MathJax.js',
            config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
        },

        dependencies: [
            { src: 'js/math.js', async: true }
        ]
      // // More info https://github.com/hakimel/reveal.js#dependencies
      // dependencies: [{
      //   src: 'plugin/markdown/marked.js'
      // }, {
      //   src: 'plugin/markdown/markdown.js'
      // }, {
      //   src: 'plugin/notes/notes.js',
      //   async: true
      // }, {
      //   src: 'plugin/highlight/highlight.js',
      //   async: true,
      //   callback: function() {
      //     hljs.initHighlightingOnLoad();
      //   }
      // }]
    });
  </script>


  <script>
    // Load the IFrame Player API code asynchronously.
    var tag = document.createElement('script');
    tag.src = "https://www.youtube.com/player_api";
    var firstScriptTag = document.getElementsByTagName('script')[0];
    firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);
    // Replace the 'ytplayer' element with an <iframe> and
    // YouTube player after the API code downloads.
    var player;
    function onYouTubePlayerAPIReady() {
      player = new YT.Player('ytplayer', {
        width: '920',
        height: '490',
        videoId: 'F4lc9cY4fMM',
        playerVars: {
          'wmode': 'opaque',
          'autoplay': 1,
          'controls': 0 ,
          'showinfo': 0,
          'start': 20,
          'rel': 0,
          'loop': 1,
        },
        events:{
          'onReady':onPlayerReady
        }
     });
    }
    function onPlayerReady(event) {
      event.target.mute();
    }

//     Reveal.addEventListener( 'slidechanged', function( event ) {
//     MathJax.Hub.Rerender();
// } );
  </script>

</body>

</html>
